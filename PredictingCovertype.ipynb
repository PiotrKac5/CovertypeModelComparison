{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-31T17:42:05.446522272Z",
     "start_time": "2024-07-31T17:42:05.256260522Z"
    }
   },
   "id": "ffb43f9b280d6069"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-31T17:43:45.147897314Z",
     "start_time": "2024-07-31T17:42:05.447509386Z"
    }
   },
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "covertype = fetch_ucirepo(id=31) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = covertype.data.features \n",
    "y = covertype.data.targets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 31, 'name': 'Covertype', 'repository_url': 'https://archive.ics.uci.edu/dataset/31/covertype', 'data_url': 'https://archive.ics.uci.edu/static/public/31/data.csv', 'abstract': 'Classification of pixels into 7 forest cover types based on attributes such as elevation, aspect, slope, hillshade, soil-type, and more.', 'area': 'Biology', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 581012, 'num_features': 54, 'feature_types': ['Categorical', 'Integer'], 'demographics': [], 'target_col': ['Cover_Type'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 1998, 'last_updated': 'Sat Mar 16 2024', 'dataset_doi': '10.24432/C50K5N', 'creators': ['Jock Blackard'], 'intro_paper': None, 'additional_info': {'summary': 'Predicting forest cover type from cartographic variables only (no remotely sensed data).  The actual forest cover type for a given observation (30 x 30 meter cell) was determined from US Forest Service (USFS) Region 2 Resource Information System (RIS) data.  Independent variables were derived from data originally obtained from US Geological Survey (USGS) and USFS data.  Data is in raw form (not scaled) and contains binary (0 or 1) columns of data for qualitative independent variables (wilderness areas and soil types).\\r\\n\\r\\nThis study area includes four wilderness areas located in the Roosevelt National Forest of northern Colorado.  These areas represent forests with minimal human-caused disturbances, so that existing forest cover types are more a result of ecological processes rather than forest management practices.\\r\\n\\r\\nSome background information for these four wilderness areas: Neota (area 2) probably has the highest mean elevational value of the 4 wilderness areas. Rawah (area 1) and Comanche Peak (area 3) would have a lower mean elevational value, while Cache la Poudre (area 4) would have the lowest mean elevational value. \\r\\n\\r\\nAs for primary major tree species in these areas, Neota would have spruce/fir (type 1), while Rawah and Comanche Peak would probably have lodgepole pine (type 2) as their primary species, followed by spruce/fir and aspen (type 5). Cache la Poudre would tend to have Ponderosa pine (type 3), Douglas-fir (type 6), and cottonwood/willow (type 4).  \\r\\n\\r\\nThe Rawah and Comanche Peak areas would tend to be more typical of the overall dataset than either the Neota or Cache la Poudre, due to their assortment of tree species and range of predictive variable values (elevation, etc.)  Cache la Poudre would probably  be more unique than the others, due to its relatively low  elevation range and species composition. ', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'Given is the attribute name, attribute type, the measurement unit and a brief description.  The forest cover type is the classification  problem.  The order of this listing corresponds to the order of numerals along the rows of the database.\\r\\n\\r\\nName / Data Type / Measurement / Description\\r\\n\\r\\nElevation / quantitative /meters / Elevation in meters\\r\\nAspect / quantitative / azimuth / Aspect in degrees azimuth\\r\\nSlope / quantitative / degrees / Slope in degrees\\r\\nHorizontal_Distance_To_Hydrology / quantitative / meters / Horz Dist to nearest surface water features\\r\\nVertical_Distance_To_Hydrology / quantitative / meters / Vert Dist to nearest surface water features\\r\\nHorizontal_Distance_To_Roadways / quantitative / meters / Horz Dist to nearest roadway\\r\\nHillshade_9am / quantitative / 0 to 255 index / Hillshade index at 9am, summer solstice\\r\\nHillshade_Noon / quantitative / 0 to 255 index / Hillshade index at noon, summer soltice\\r\\nHillshade_3pm / quantitative / 0 to 255 index / Hillshade index at 3pm, summer solstice\\r\\nHorizontal_Distance_To_Fire_Points / quantitative / meters / Horz Dist to nearest wildfire ignition points\\r\\nWilderness_Area (4 binary columns) / qualitative / 0 (absence) or 1 (presence) / Wilderness area designation\\r\\nSoil_Type (40 binary columns) / qualitative / 0 (absence) or 1 (presence) / Soil Type designation\\r\\nCover_Type (7 types) / integer / 1 to 7 / Forest Cover Type designation', 'citation': None}}\n",
      "                                  name     role     type demographic  \\\n",
      "0                            Elevation  Feature  Integer        None   \n",
      "1                               Aspect  Feature  Integer        None   \n",
      "2                                Slope  Feature  Integer        None   \n",
      "3     Horizontal_Distance_To_Hydrology  Feature  Integer        None   \n",
      "4       Vertical_Distance_To_Hydrology  Feature  Integer        None   \n",
      "5      Horizontal_Distance_To_Roadways  Feature  Integer        None   \n",
      "6                        Hillshade_9am  Feature  Integer        None   \n",
      "7                       Hillshade_Noon  Feature  Integer        None   \n",
      "8                        Hillshade_3pm  Feature  Integer        None   \n",
      "9   Horizontal_Distance_To_Fire_Points  Feature  Integer        None   \n",
      "10                    Wilderness_Area1  Feature  Integer        None   \n",
      "11                          Soil_Type1  Feature  Integer        None   \n",
      "12                          Soil_Type2  Feature  Integer        None   \n",
      "13                          Soil_Type3  Feature  Integer        None   \n",
      "14                          Soil_Type4  Feature  Integer        None   \n",
      "15                          Soil_Type5  Feature  Integer        None   \n",
      "16                          Soil_Type6  Feature  Integer        None   \n",
      "17                          Soil_Type7  Feature  Integer        None   \n",
      "18                          Soil_Type8  Feature  Integer        None   \n",
      "19                          Soil_Type9  Feature  Integer        None   \n",
      "20                         Soil_Type10  Feature  Integer        None   \n",
      "21                         Soil_Type11  Feature  Integer        None   \n",
      "22                         Soil_Type12  Feature  Integer        None   \n",
      "23                         Soil_Type13  Feature  Integer        None   \n",
      "24                         Soil_Type14  Feature  Integer        None   \n",
      "25                         Soil_Type15  Feature  Integer        None   \n",
      "26                         Soil_Type16  Feature  Integer        None   \n",
      "27                         Soil_Type17  Feature  Integer        None   \n",
      "28                         Soil_Type18  Feature  Integer        None   \n",
      "29                         Soil_Type19  Feature  Integer        None   \n",
      "30                         Soil_Type20  Feature  Integer        None   \n",
      "31                         Soil_Type21  Feature  Integer        None   \n",
      "32                         Soil_Type22  Feature  Integer        None   \n",
      "33                         Soil_Type23  Feature  Integer        None   \n",
      "34                         Soil_Type24  Feature  Integer        None   \n",
      "35                         Soil_Type25  Feature  Integer        None   \n",
      "36                         Soil_Type26  Feature  Integer        None   \n",
      "37                         Soil_Type27  Feature  Integer        None   \n",
      "38                         Soil_Type28  Feature  Integer        None   \n",
      "39                         Soil_Type29  Feature  Integer        None   \n",
      "40                         Soil_Type30  Feature  Integer        None   \n",
      "41                         Soil_Type31  Feature  Integer        None   \n",
      "42                         Soil_Type32  Feature  Integer        None   \n",
      "43                         Soil_Type33  Feature  Integer        None   \n",
      "44                         Soil_Type34  Feature  Integer        None   \n",
      "45                         Soil_Type35  Feature  Integer        None   \n",
      "46                         Soil_Type36  Feature  Integer        None   \n",
      "47                         Soil_Type37  Feature  Integer        None   \n",
      "48                         Soil_Type38  Feature  Integer        None   \n",
      "49                         Soil_Type39  Feature  Integer        None   \n",
      "50                         Soil_Type40  Feature  Integer        None   \n",
      "51                          Cover_Type   Target  Integer        None   \n",
      "52                    Wilderness_Area2  Feature  Integer        None   \n",
      "53                    Wilderness_Area3  Feature  Integer        None   \n",
      "54                    Wilderness_Area4  Feature  Integer        None   \n",
      "\n",
      "   description units missing_values  \n",
      "0         None  None             no  \n",
      "1         None  None             no  \n",
      "2         None  None             no  \n",
      "3         None  None             no  \n",
      "4         None  None             no  \n",
      "5         None  None             no  \n",
      "6         None  None             no  \n",
      "7         None  None             no  \n",
      "8         None  None             no  \n",
      "9         None  None             no  \n",
      "10        None  None             no  \n",
      "11        None  None             no  \n",
      "12        None  None             no  \n",
      "13        None  None             no  \n",
      "14        None  None             no  \n",
      "15        None  None             no  \n",
      "16        None  None             no  \n",
      "17        None  None             no  \n",
      "18        None  None             no  \n",
      "19        None  None             no  \n",
      "20        None  None             no  \n",
      "21        None  None             no  \n",
      "22        None  None             no  \n",
      "23        None  None             no  \n",
      "24        None  None             no  \n",
      "25        None  None             no  \n",
      "26        None  None             no  \n",
      "27        None  None             no  \n",
      "28        None  None             no  \n",
      "29        None  None             no  \n",
      "30        None  None             no  \n",
      "31        None  None             no  \n",
      "32        None  None             no  \n",
      "33        None  None             no  \n",
      "34        None  None             no  \n",
      "35        None  None             no  \n",
      "36        None  None             no  \n",
      "37        None  None             no  \n",
      "38        None  None             no  \n",
      "39        None  None             no  \n",
      "40        None  None             no  \n",
      "41        None  None             no  \n",
      "42        None  None             no  \n",
      "43        None  None             no  \n",
      "44        None  None             no  \n",
      "45        None  None             no  \n",
      "46        None  None             no  \n",
      "47        None  None             no  \n",
      "48        None  None             no  \n",
      "49        None  None             no  \n",
      "50        None  None             no  \n",
      "51        None  None             no  \n",
      "52        None  None             no  \n",
      "53        None  None             no  \n",
      "54        None  None             no  \n"
     ]
    }
   ],
   "source": [
    "# metadata \n",
    "print(covertype.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(covertype.variables) "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-31T17:44:36.671186046Z",
     "start_time": "2024-07-31T17:44:36.626557560Z"
    }
   },
   "id": "839a57fe950a819b"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def simple_heuristic(X):\n",
    "    X_step = X + 1\n",
    "    y = pd.DataFrame(X_step.product(axis='columns')%7 + 1)\n",
    "    return y"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-31T17:45:54.576871438Z",
     "start_time": "2024-07-31T17:45:54.533434939Z"
    }
   },
   "id": "90713db790cd580b"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_0 score: 0.14624827025947829\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[6],\n       [5],\n       [4],\n       ...,\n       [5],\n       [5],\n       [6]])"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "sh_y = np.array(simple_heuristic(X))\n",
    "score_model_0 = (sh_y == y.values).sum() / len(y)\n",
    "print(f\"Model_0 score: {score_model_0}\")\n",
    "sh_y"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-31T17:56:50.717678171Z",
     "start_time": "2024-07-31T17:56:50.600326178Z"
    }
   },
   "id": "12fdd9c3e13f1cff"
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "(464809, 116203)"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "len(X_train), len(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-31T18:51:17.888459440Z",
     "start_time": "2024-07-31T18:51:17.633458172Z"
    }
   },
   "id": "e079afb255069f83"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:1473: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_1 score: 0.6309819884168223\n",
      "Model_2 score: 0.8401590320387597\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "model_1 = AdaBoostClassifier(algorithm=\"SAMME\", random_state=42)\n",
    "model_2 = RandomForestClassifier(max_depth=15, max_features=10, random_state=42)\n",
    "\n",
    "model_1.fit(X_train, y_train)\n",
    "model_2.fit(X_train, y_train)\n",
    "\n",
    "score_model_1 = model_1.score(X_test, y_test)\n",
    "score_model_2 = model_2.score(X_test, y_test)\n",
    "\n",
    "print(f\"Model_1 score: {score_model_1}\")\n",
    "print(f\"Model_2 score: {score_model_2}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-31T18:49:14.852469672Z",
     "start_time": "2024-07-31T18:47:50.595774231Z"
    }
   },
   "id": "bb770b3fe7874664"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class NeuralNetworkModel(nn.Module):\n",
    "    def __init__(self, hidden_units):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(in_features=54, out_features=hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_units, out_features=hidden_units),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_units, out_features=hidden_units),\n",
    "            nn.Linear(in_features=hidden_units, out_features=7)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-31T18:49:14.854846812Z",
     "start_time": "2024-07-31T18:49:14.852329861Z"
    }
   },
   "id": "4355fd3727969c88"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([464809, 54]),\n torch.Size([116203, 54]),\n torch.Size([464809]),\n torch.Size([116203]))"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train.values, dtype=torch.long).squeeze()\n",
    "y_test = torch.tensor(y_test.values, dtype=torch.long).squeeze()\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-31T18:51:28.953552377Z",
     "start_time": "2024-07-31T18:51:28.933116013Z"
    }
   },
   "id": "2eadd87908dfb44f"
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "y_train -= 1\n",
    "y_test -= 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-31T18:52:38.616510235Z",
     "start_time": "2024-07-31T18:52:38.571320519Z"
    }
   },
   "id": "ef006652ed18d1f7"
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def train(model:torch.nn.Module,\n",
    "               loss_fn:torch.nn.Module,\n",
    "               optimizer:torch.optim.Optimizer,\n",
    "               epochs:int):\n",
    "    \n",
    "    test_acc = 0\n",
    "    test_loss = 0\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        y_logits = model(X_train)\n",
    "        y_preds = torch.softmax(y_logits, dim=1).argmax()\n",
    "        \n",
    "        loss = loss_fn(y_logits, y_train)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch % 20 == 0:\n",
    "            curr_loss, curr_acc = test(model, loss_fn)\n",
    "            if curr_acc < test_acc: # checking if model is overfitting\n",
    "                print(f\"Model started to overfit, ending teatching at epoch: {epoch}\")\n",
    "                return epoch\n",
    "    return epochs\n",
    "\n",
    "def test(model:torch.nn.Module,\n",
    "               loss_fn:torch.nn.Module):\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        y_logits = model(X_test)\n",
    "        test_loss = loss_fn(y_logits, y_test)\n",
    "        y_preds = torch.argmax(torch.softmax(y_logits, dim=1), dim=1)\n",
    "        test_acc = (y_preds == y_test).sum().item() / len(y_test)\n",
    "        \n",
    "    return test_loss, test_acc"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-31T18:56:46.407741147Z",
     "start_time": "2024-07-31T18:56:46.390841558Z"
    }
   },
   "id": "6496b1c7909f125b"
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "def set_best_hyperparameters(hidden_units, lr, epochs):\n",
    "    return {\"hidden_units\":hidden_units, \"lr\":lr, \"epochs\":epochs}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-31T18:56:47.538085809Z",
     "start_time": "2024-07-31T18:56:47.529733083Z"
    }
   },
   "id": "ecec38b1d393d100"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of epochs: 100 | Hidden_units: 8 | Learing rate: 0.001\n",
      "Test loss: 1.5417283773422241  |  Test accuracy: 0.3915991841862947\n",
      "--------------------------------------------------------------------------------\n",
      "Number of epochs: 200 | Hidden_units: 8 | Learing rate: 0.001\n",
      "Test loss: 1.1495548486709595  |  Test accuracy: 0.49057253255079475\n",
      "--------------------------------------------------------------------------------\n",
      "Number of epochs: 300 | Hidden_units: 8 | Learing rate: 0.001\n",
      "Test loss: 1.1195231676101685  |  Test accuracy: 0.49762054335946576\n",
      "--------------------------------------------------------------------------------\n",
      "Number of epochs: 400 | Hidden_units: 8 | Learing rate: 0.001\n",
      "Test loss: 1.0857106447219849  |  Test accuracy: 0.500253866079189\n",
      "--------------------------------------------------------------------------------\n",
      "Number of epochs: 500 | Hidden_units: 8 | Learing rate: 0.001\n",
      "Test loss: 0.908551037311554  |  Test accuracy: 0.6548453998605888\n",
      "--------------------------------------------------------------------------------\n",
      "Number of epochs: 600 | Hidden_units: 8 | Learing rate: 0.001\n",
      "Test loss: 0.8280574083328247  |  Test accuracy: 0.6828223023501975\n",
      "--------------------------------------------------------------------------------\n",
      "Number of epochs: 700 | Hidden_units: 8 | Learing rate: 0.001\n",
      "Test loss: 0.7927846908569336  |  Test accuracy: 0.6914967771916388\n",
      "--------------------------------------------------------------------------------\n",
      "Number of epochs: 800 | Hidden_units: 8 | Learing rate: 0.001\n",
      "Test loss: 0.754696249961853  |  Test accuracy: 0.703673743362908\n",
      "--------------------------------------------------------------------------------\n",
      "Number of epochs: 900 | Hidden_units: 8 | Learing rate: 0.001\n",
      "Test loss: 0.7332586646080017  |  Test accuracy: 0.7064963899382977\n",
      "--------------------------------------------------------------------------------\n",
      "Number of epochs: 100 | Hidden_units: 8 | Learing rate: 0.01\n",
      "Test loss: 1.0009149312973022  |  Test accuracy: 0.6310680447148524\n",
      "--------------------------------------------------------------------------------\n",
      "Number of epochs: 200 | Hidden_units: 8 | Learing rate: 0.01\n",
      "Test loss: 0.9066178202629089  |  Test accuracy: 0.6502844160649898\n",
      "--------------------------------------------------------------------------------\n",
      "Number of epochs: 300 | Hidden_units: 8 | Learing rate: 0.01\n",
      "Test loss: 0.906470775604248  |  Test accuracy: 0.632341677925699\n",
      "--------------------------------------------------------------------------------\n",
      "Number of epochs: 400 | Hidden_units: 8 | Learing rate: 0.01\n",
      "Test loss: 0.8734501004219055  |  Test accuracy: 0.6564116244847379\n",
      "--------------------------------------------------------------------------------\n",
      "Number of epochs: 500 | Hidden_units: 8 | Learing rate: 0.01\n",
      "Test loss: 0.9182446599006653  |  Test accuracy: 0.6051737046375739\n",
      "--------------------------------------------------------------------------------\n",
      "Number of epochs: 600 | Hidden_units: 8 | Learing rate: 0.01\n",
      "Test loss: 0.8663970828056335  |  Test accuracy: 0.6553961601679819\n",
      "--------------------------------------------------------------------------------\n",
      "Number of epochs: 700 | Hidden_units: 8 | Learing rate: 0.01\n",
      "Test loss: 1.2049914598464966  |  Test accuracy: 0.48737123826407236\n",
      "--------------------------------------------------------------------------------\n",
      "Number of epochs: 800 | Hidden_units: 8 | Learing rate: 0.01\n",
      "Test loss: 1.2052890062332153  |  Test accuracy: 0.48646764713475554\n",
      "--------------------------------------------------------------------------------\n",
      "Number of epochs: 900 | Hidden_units: 8 | Learing rate: 0.01\n",
      "Test loss: 1.2052890062332153  |  Test accuracy: 0.48646764713475554\n",
      "--------------------------------------------------------------------------------\n",
      "Number of epochs: 100 | Hidden_units: 8 | Learing rate: 0.1\n",
      "Test loss: 1.2052985429763794  |  Test accuracy: 0.48646764713475554\n",
      "--------------------------------------------------------------------------------\n",
      "Number of epochs: 200 | Hidden_units: 8 | Learing rate: 0.1\n",
      "Test loss: 1.2052888870239258  |  Test accuracy: 0.48646764713475554\n",
      "--------------------------------------------------------------------------------\n",
      "Number of epochs: 300 | Hidden_units: 8 | Learing rate: 0.1\n",
      "Test loss: 1.2052890062332153  |  Test accuracy: 0.48646764713475554\n",
      "--------------------------------------------------------------------------------\n",
      "Number of epochs: 400 | Hidden_units: 8 | Learing rate: 0.1\n",
      "Test loss: 1.2052891254425049  |  Test accuracy: 0.48646764713475554\n",
      "--------------------------------------------------------------------------------\n",
      "Number of epochs: 500 | Hidden_units: 8 | Learing rate: 0.1\n",
      "Test loss: 1.2052890062332153  |  Test accuracy: 0.48646764713475554\n",
      "--------------------------------------------------------------------------------\n",
      "Number of epochs: 600 | Hidden_units: 8 | Learing rate: 0.1\n",
      "Test loss: 1.2052890062332153  |  Test accuracy: 0.48646764713475554\n",
      "--------------------------------------------------------------------------------\n",
      "Number of epochs: 700 | Hidden_units: 8 | Learing rate: 0.1\n",
      "Test loss: 1.2052891254425049  |  Test accuracy: 0.48646764713475554\n",
      "--------------------------------------------------------------------------------\n",
      "Number of epochs: 800 | Hidden_units: 8 | Learing rate: 0.1\n",
      "Test loss: 1.2052890062332153  |  Test accuracy: 0.48646764713475554\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "best_hyperparameters = set_best_hyperparameters(0, 0, 0)\n",
    "best_test_acc = 0\n",
    "\n",
    "for hidden_units in range(8, 13):\n",
    "    model_5 = NeuralNetworkModel(hidden_units=hidden_units)\n",
    "    lr = 0.001\n",
    "    while lr <= 0.1:\n",
    "        optimizer = torch.optim.Adam(params=model_5.parameters(), lr=lr, weight_decay=1e-5)\n",
    "        for epochs in range(100, 1000, 100):\n",
    "            num_ep = train(model=model_5, loss_fn=loss_fn, optimizer=optimizer, epochs=epochs)\n",
    "            test_loss, test_acc = test(model=model_5, loss_fn=loss_fn)\n",
    "            \n",
    "            print(f\"Number of epochs: {epochs} | Hidden_units: {hidden_units} | Learing rate: {lr}\")\n",
    "            print(f\"Test loss: {test_loss}  |  Test accuracy: {test_acc}\")\n",
    "            print(\"--------------------------------------------------------------------------------\\n\")\n",
    "            \n",
    "            if test_acc > best_test_acc:\n",
    "                best_test_acc = test_acc\n",
    "                best_hyperparameters = set_best_hyperparameters(hidden_units, lr, num_ep)\n",
    "                \n",
    "            if num_ep < epochs: # this means, that model started to overfit\n",
    "                break\n",
    "                \n",
    "        lr *= 10\n",
    "        \n",
    "print(f\"Best test acc: {best_test_acc} with hyperparameters: {best_hyperparameters}\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-07-31T18:56:56.100831216Z"
    }
   },
   "id": "1aaa6e6f4019e6c3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
